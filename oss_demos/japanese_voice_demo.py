#!/usr/bin/env python3
"""
æ—¥æœ¬èªå®Œå…¨å¯¾å¿œéŸ³å£°ä¼šè©±ãƒ‡ãƒ¢
- Whisper.cpp: ãƒ­ãƒ¼ã‚«ãƒ«æ—¥æœ¬èªéŸ³å£°èªè­˜ï¼ˆé«˜ç²¾åº¦ï¼‰
- gTTS: æ—¥æœ¬èªéŸ³å£°åˆæˆï¼ˆç„¡æ–™ï¼‰
- OpenAI GPT-3.5: æ—¥æœ¬èªAIä¼šè©±
"""

import asyncio
import signal
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from whisper_cpp_transcriber import WhisperCPPTranscriber, VocodeWhisperCPPTranscriberConfig
from vocode.helpers import create_streaming_microphone_input_and_speaker_output
from vocode.logging import configure_pretty_logging
from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent
from vocode.streaming.models.agent import ChatGPTAgentConfig
from vocode.streaming.models.message import BaseMessage
from vocode.streaming.models.synthesizer import GTTSSynthesizerConfig
from vocode.streaming.streaming_conversation import StreamingConversation
from vocode.streaming.synthesizer.gtts_synthesizer import GTTSSynthesizer

configure_pretty_logging()
load_dotenv()


def check_whisper_model():
    """Whisperãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æŒ‡ç¤º"""
    model_paths = [
        "/Users/yuki/vocode-core/models/ggml-base.bin",
        "models/ggml-base.bin",
    ]
    
    for path in model_paths:
        if Path(path).exists():
            return path
    
    print("âŒ Whisperãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    print("\nä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼š")
    print("mkdir -p models")
    print("curl -L -o models/ggml-base.bin https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin")
    print("\nã¾ãŸã¯æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ï¼š")
    print("curl -L -o models/ggml-medium.bin https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin")
    return None


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # Whisperãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
    model_path = check_whisper_model()
    if not model_path:
        return
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("echo 'OPENAI_API_KEY=your_key' > .env")
        return
    
    print("=" * 60)
    print("ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªå®Œå…¨å¯¾å¿œéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    print()
    print("ğŸ¤ éŸ³å£°èªè­˜: Whisper.cpp (ãƒ­ãƒ¼ã‚«ãƒ«ã€é«˜ç²¾åº¦)")
    print("ğŸ”Š éŸ³å£°åˆæˆ: gTTS (æ—¥æœ¬èªå¯¾å¿œ)")
    print("ğŸ¤– AI: OpenAI GPT-3.5 (æ—¥æœ¬èªä¼šè©±)")
    print()
    print("ç‰¹å¾´:")
    print("- å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°èªè­˜ï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸è¦ï¼‰")
    print("- é«˜ç²¾åº¦ãªæ—¥æœ¬èªèªè­˜")
    print("- è‡ªç„¶ãªæ—¥æœ¬èªä¼šè©±")
    print()
    
    # ãƒã‚¤ã‚¯ã¨ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®è¨­å®š
    (
        microphone_input,
        speaker_output,
    ) = create_streaming_microphone_input_and_speaker_output(
        use_default_devices=True,
    )
    
    # æ—¥æœ¬èªå¯¾å¿œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    agent = ChatGPTAgent(
        ChatGPTAgentConfig(
            openai_api_key=openai_api_key,
            initial_message=BaseMessage(text="ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯æ—¥æœ¬èªã§ä¼šè©±ã§ãã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä½•ã§ã‚‚ãŠèããã ã•ã„ã€‚"),
            prompt_preamble="""ã‚ãªãŸã¯è¦ªåˆ‡ã§ä¸å¯§ãªæ—¥æœ¬èªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨è‡ªç„¶ãªä¼šè©±ã‚’ã—ã¦ãã ã•ã„ã€‚
            å›ç­”ã¯ç°¡æ½”ã«ã—ã€ä¼šè©±çš„ãªãƒˆãƒ¼ãƒ³ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚
            ç›¸æ‰‹ã®è©±ã‚’ã‚ˆãèãã€é©åˆ‡ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚""",
            model_name="gpt-3.5-turbo",
            generate_responses=True,
        )
    )
    
    # ä¼šè©±ã®è¨­å®š
    conversation = StreamingConversation(
        output_device=speaker_output,
        transcriber=WhisperCPPTranscriber(
            VocodeWhisperCPPTranscriberConfig.from_input_device(
                microphone_input,
                language="ja",  # æ—¥æœ¬èª
                model_path=model_path,
                chunk_duration_seconds=2.0,  # 2ç§’ã”ã¨ã«å‡¦ç†
                silence_threshold=500,
                min_chunk_duration=0.5,
            ),
        ),
        agent=agent,
        synthesizer=GTTSSynthesizer(
            GTTSSynthesizerConfig.from_output_device(
                speaker_output,
                lang="ja",  # æ—¥æœ¬èª
                tld="com",
                slow=False,  # é€šå¸¸é€Ÿåº¦
            ),
        ),
    )
    
    await conversation.start()
    print("ğŸ™ï¸  ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼æ—¥æœ¬èªã§è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚")
    print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã¯ã£ãã‚Šã¨è©±ã—ã¦ãã ã•ã„ã€‚å°‘ã—é–“ã‚’ç½®ãã¨èªè­˜ã•ã‚Œã¾ã™ã€‚")
    print("ğŸ›‘ çµ‚äº†: Ctrl+C")
    print("-" * 60)
    
    # Ctrl+Cã§çµ‚äº†
    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))
    
    # éŸ³å£°å…¥åŠ›ã‚’å‡¦ç†
    while conversation.is_active():
        chunk = await microphone_input.get_audio()
        conversation.receive_audio(chunk)


def test_system():
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯ä¸­...")
    
    # Whisper.cppã®ç¢ºèª
    whisper_path = "/opt/homebrew/bin/whisper-cpp"
    if Path(whisper_path).exists():
        print("âœ… Whisper.cpp: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
    else:
        print("âŒ Whisper.cpp: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        print("   brew install whisper-cpp")
        return False
    
    # ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
    if check_whisper_model():
        print("âœ… Whisperãƒ¢ãƒ‡ãƒ«: æº–å‚™å®Œäº†")
    else:
        return False
    
    # ãƒã‚¤ã‚¯ã®ç¢ºèª
    try:
        import sounddevice as sd
        devices = sd.query_devices()
        print("âœ… ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹: åˆ©ç”¨å¯èƒ½")
    except:
        print("âŒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹: ã‚¨ãƒ©ãƒ¼")
        return False
    
    return True


if __name__ == "__main__":
    print("\nğŸ‡¯ğŸ‡µ æ—¥æœ¬èªéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ã—ã¾ã™...\n")
    
    if test_system():
        try:
            asyncio.run(main())
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ã”åˆ©ç”¨ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
    else:
        print("\nã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ãã ã•ã„ã€‚")