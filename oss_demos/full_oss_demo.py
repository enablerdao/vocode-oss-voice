#!/usr/bin/env python3
"""
å®Œå…¨ã«OSS/ç„¡æ–™ã‚µãƒ¼ãƒ“ã‚¹ã®ã¿ã‚’ä½¿ç”¨ã—ãŸVocodeéŸ³å£°ä¼šè©±ãƒ‡ãƒ¢
- Google Speech Recognition: ç„¡æ–™ã®éŸ³å£°èªè­˜ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰
- gTTS: ç„¡æ–™ã®éŸ³å£°åˆæˆï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰
- OpenAI: LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆAPIã‚­ãƒ¼å¿…è¦ï¼‰
"""

import asyncio
import signal
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒ©ã‚¤ãƒãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from google_sr_transcriber import GoogleSRTranscriber, GoogleSRTranscriberConfig
from vocode.helpers import create_streaming_microphone_input_and_speaker_output
from vocode.logging import configure_pretty_logging
from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent
from vocode.streaming.agent.echo_agent import EchoAgent
from vocode.streaming.models.agent import ChatGPTAgentConfig, EchoAgentConfig
from vocode.streaming.models.message import BaseMessage
from vocode.streaming.models.synthesizer import GTTSSynthesizerConfig
from vocode.streaming.streaming_conversation import StreamingConversation
from vocode.streaming.synthesizer.gtts_synthesizer import GTTSSynthesizer

configure_pretty_logging()
load_dotenv()


async def main():
    """å®Œå…¨OSSãƒ™ãƒ¼ã‚¹ã®éŸ³å£°ä¼šè©±ã‚’å®Ÿè¡Œ"""
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    openai_api_key = os.getenv("OPENAI_API_KEY")
    use_openai = bool(openai_api_key)
    
    print("=" * 60)
    print("å®Œå…¨OSSãƒ™ãƒ¼ã‚¹ã®VocodeéŸ³å£°ä¼šè©±ãƒ‡ãƒ¢")
    print("=" * 60)
    print()
    print("ğŸ¤ éŸ³å£°èªè­˜: Google Speech Recognition (ç„¡æ–™ã€APIã‚­ãƒ¼ä¸è¦)")
    print("ğŸ”Š éŸ³å£°åˆæˆ: gTTS (Google Text-to-Speechã€ç„¡æ–™)")
    print(f"ğŸ¤– AI: {'OpenAI GPT-3.5' if use_openai else 'Echo Agent (APIã‚­ãƒ¼ä¸è¦)'}")
    print()
    print("ä½¿ã„æ–¹:")
    print("1. è©±ã—ã‹ã‘ã¦ãã ã•ã„")
    print("2. AIãŒå¿œç­”ã—ã¾ã™")
    print("3. çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    print()
    
    # ãƒã‚¤ã‚¯ã¨ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®è¨­å®š
    (
        microphone_input,
        speaker_output,
    ) = create_streaming_microphone_input_and_speaker_output(
        use_default_devices=True,
    )
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é¸æŠ
    if use_openai:
        agent = ChatGPTAgent(
            ChatGPTAgentConfig(
                openai_api_key=openai_api_key,
                initial_message=BaseMessage(text="Hello! I'm your AI assistant. How can I help you today?"),
                prompt_preamble="You are a helpful AI assistant. Keep responses brief and conversational.",
                model_name="gpt-3.5-turbo",
            )
        )
    else:
        agent = EchoAgent(
            EchoAgentConfig(
                initial_message=BaseMessage(text="Hello! I'm an echo agent. I'll repeat what you say!"),
            )
        )
    
    # ä¼šè©±ã®è¨­å®š
    conversation = StreamingConversation(
        output_device=speaker_output,
        transcriber=GoogleSRTranscriber(
            GoogleSRTranscriberConfig.from_input_device(
                microphone_input,
                language="en-US",  # è‹±èªèªè­˜ï¼ˆ"ja-JP"ã§æ—¥æœ¬èªã‚‚å¯èƒ½ï¼‰
                energy_threshold=300,
                pause_threshold=0.8,
            ),
        ),
        agent=agent,
        synthesizer=GTTSSynthesizer(
            GTTSSynthesizerConfig.from_output_device(
                speaker_output,
                lang="en",  # è‹±èªåˆæˆï¼ˆ"ja"ã§æ—¥æœ¬èªã‚‚å¯èƒ½ï¼‰
                tld="com",
            ),
        ),
    )
    
    await conversation.start()
    print("ğŸ™ï¸  ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼è©±ã—ã‹ã‘ã¦ãã ã•ã„...")
    print("    (éŸ³å£°èªè­˜ã«ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")
    print()
    
    # Ctrl+Cã§çµ‚äº†
    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))
    
    # éŸ³å£°å…¥åŠ›ã‚’å‡¦ç†
    while conversation.is_active():
        chunk = await microphone_input.get_audio()
        conversation.receive_audio(chunk)


def test_dependencies():
    """ä¾å­˜é–¢ä¿‚ã®ãƒ†ã‚¹ãƒˆ"""
    print("ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    
    try:
        import speech_recognition as sr
        print("âœ… speech_recognition: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
        
        # ãƒã‚¤ã‚¯ã®ãƒ†ã‚¹ãƒˆ
        r = sr.Recognizer()
        with sr.Microphone() as source:
            print("âœ… ãƒã‚¤ã‚¯: åˆ©ç”¨å¯èƒ½")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False
        
    try:
        from gtts import gTTS
        print("âœ… gTTS: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
    except:
        print("âŒ gTTS: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
        
    return True


if __name__ == "__main__":
    if test_dependencies():
        print()
        try:
            asyncio.run(main())
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ çµ‚äº†ã—ã¾ã—ãŸã€‚")
    else:
        print("\nä¾å­˜é–¢ä¿‚ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("poetry add SpeechRecognition gtts")