#!/usr/bin/env python3
"""
æ—¥æœ¬èªéŸ³å£°ä¼šè©±ãƒ‡ãƒ¢ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
Google Speech Recognition + gTTSä½¿ç”¨
"""

import asyncio
import signal
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent))

sys.path.append(str(Path(__file__).parent.parent))
from high_performance_oss_demo import OptimizedGoogleSRTranscriberConfig, OptimizedGoogleSRTranscriber
from vocode.helpers import create_streaming_microphone_input_and_speaker_output
from vocode.logging import configure_pretty_logging
from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent
from vocode.streaming.models.agent import ChatGPTAgentConfig
from vocode.streaming.models.message import BaseMessage
from vocode.streaming.models.synthesizer import GTTSSynthesizerConfig
from vocode.streaming.streaming_conversation import StreamingConversation
from vocode.streaming.synthesizer.gtts_synthesizer import GTTSSynthesizer

configure_pretty_logging()
load_dotenv()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    print("=" * 60)
    print("ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªéŸ³å£°ä¼šè©±ãƒ‡ãƒ¢ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰")
    print("=" * 60)
    print()
    print("ğŸ¤ éŸ³å£°èªè­˜: Google Speech Recognition (æ—¥æœ¬èª)")
    print("ğŸ”Š éŸ³å£°åˆæˆ: gTTS (æ—¥æœ¬èª)")
    print("ğŸ¤– AI: OpenAI GPT-3.5 (æ—¥æœ¬èª)")
    print()
    
    # ãƒã‚¤ã‚¯ã¨ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®è¨­å®š
    (
        microphone_input,
        speaker_output,
    ) = create_streaming_microphone_input_and_speaker_output(
        use_default_devices=True,
    )
    
    # æ—¥æœ¬èªAIè¨­å®š
    agent = ChatGPTAgent(
        ChatGPTAgentConfig(
            openai_api_key=openai_api_key,
            initial_message=BaseMessage(text="ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"),
            prompt_preamble="""ã‚ãªãŸã¯è¦ªåˆ‡ãªæ—¥æœ¬èªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            ç°¡æ½”ã§è‡ªç„¶ãªæ—¥æœ¬èªã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
            ç›¸æ‰‹ã®è³ªå•ã«çš„ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚""",
            model_name="gpt-3.5-turbo",
            generate_responses=True,
        )
    )
    
    # ä¼šè©±ã®è¨­å®š
    conversation = StreamingConversation(
        output_device=speaker_output,
        transcriber=OptimizedGoogleSRTranscriber(
            OptimizedGoogleSRTranscriberConfig.from_input_device(
                microphone_input,
                language="ja-JP",  # æ—¥æœ¬èª
                energy_threshold=300,
                pause_threshold=0.8,
                chunk_duration_seconds=0.5,
            ),
        ),
        agent=agent,
        synthesizer=GTTSSynthesizer(
            GTTSSynthesizerConfig.from_output_device(
                speaker_output,
                lang="ja",  # æ—¥æœ¬èª
                tld="com",
            ),
        ),
    )
    
    await conversation.start()
    print("ğŸ™ï¸  ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼")
    print("ğŸ’¡ æ—¥æœ¬èªã§è©±ã—ã‹ã‘ã¦ãã ã•ã„")
    print("ğŸ›‘ çµ‚äº†: Ctrl+C")
    print("-" * 60)
    
    # Ctrl+Cã§çµ‚äº†
    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))
    
    # éŸ³å£°å…¥åŠ›ã‚’å‡¦ç†
    while conversation.is_active():
        chunk = await microphone_input.get_audio()
        conversation.receive_audio(chunk)


if __name__ == "__main__":
    print("\nğŸ‡¯ğŸ‡µ æ—¥æœ¬èªéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰\n")
    
    try:
        import speech_recognition as sr
        print("âœ… éŸ³å£°èªè­˜: æº–å‚™å®Œäº†")
    except:
        print("âŒ speech_recognitionãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        exit(1)
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")