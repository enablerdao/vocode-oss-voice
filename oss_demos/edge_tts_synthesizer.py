"""
Edge TTS Synthesizer for Vocode
é«˜å“è³ªãªæ—¥æœ¬èªéŸ³å£°åˆæˆï¼ˆMicrosoft Edge TTSä½¿ç”¨ï¼‰
"""

import asyncio
import io
import edge_tts
from typing import List, Optional
from pydub import AudioSegment

from vocode.streaming.models.message import BaseMessage
from vocode.streaming.models.synthesizer import SynthesizerConfig
from vocode.streaming.synthesizer.base_synthesizer import BaseSynthesizer, SynthesisResult


class EdgeTTSSynthesizerConfig(SynthesizerConfig, type="synthesizer_edge_tts"):
    """Edge TTSè¨­å®š"""
    voice: str = "ja-JP-NanamiNeural"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ—¥æœ¬èªå¥³æ€§éŸ³å£°
    rate: str = "+0%"  # é€Ÿåº¦èª¿æ•´ (-50% to +100%)
    volume: str = "+0%"  # éŸ³é‡èª¿æ•´ (-50% to +100%)
    pitch: str = "+0Hz"  # ãƒ”ãƒƒãƒèª¿æ•´ (-50Hz to +50Hz)
    
    @classmethod
    def get_available_voices(cls) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªéŸ³å£°ã®ãƒªã‚¹ãƒˆ"""
        return [
            "ja-JP-NanamiNeural",  # å¥³æ€§ï¼ˆæ¨™æº–ï¼‰
            "ja-JP-KeitaNeural",   # ç”·æ€§ï¼ˆæ¨™æº–ï¼‰
            "ja-JP-AoiNeural",     # å¥³æ€§ï¼ˆæ˜ã‚‹ã„ï¼‰
            "ja-JP-DaichiNeural",  # ç”·æ€§ï¼ˆæ˜ã‚‹ã„ï¼‰
            "ja-JP-MayuNeural",    # å¥³æ€§ï¼ˆå„ªã—ã„ï¼‰
            "ja-JP-NaokiNeural",   # ç”·æ€§ï¼ˆãƒ“ã‚¸ãƒã‚¹ï¼‰
            "ja-JP-ShioriNeural",  # å¥³æ€§ï¼ˆè‹¥ã„ï¼‰
        ]


class EdgeTTSSynthesizer(BaseSynthesizer[EdgeTTSSynthesizerConfig]):
    """Edge TTSã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªéŸ³å£°åˆæˆ"""
    
    def __init__(self, synthesizer_config: EdgeTTSSynthesizerConfig):
        super().__init__(synthesizer_config)
        self.voice = synthesizer_config.voice
        self.rate = synthesizer_config.rate
        self.volume = synthesizer_config.volume
        self.pitch = synthesizer_config.pitch
        
        print(f"ğŸ¤ Edge TTS initialized with voice: {self.voice}")
    
    async def create_speech(
        self,
        message: BaseMessage,
        chunk_size: int,
        is_first_text_chunk: bool = False,
        is_sole_text_chunk: bool = False,
    ) -> SynthesisResult:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆ"""
        
        # Edge TTSã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆ
        communicate = edge_tts.Communicate(
            message.text,
            self.voice,
            rate=self.rate,
            volume=self.volume,
            pitch=self.pitch
        )
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        audio_data = io.BytesIO()
        
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data.write(chunk["data"])
        
        # ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å·»ãæˆ»ã—
        audio_data.seek(0)
        
        # MP3ã‹ã‚‰WAVã«å¤‰æ›ï¼ˆVocodeã¯WAVå½¢å¼ã‚’æœŸå¾…ï¼‰
        audio_segment = AudioSegment.from_mp3(audio_data)
        
        # WAVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        wav_data = io.BytesIO()
        audio_segment.export(wav_data, format="wav")
        wav_data.seek(0)
        
        # åˆæˆçµæœã‚’ä½œæˆ
        result = self.create_synthesis_result_from_wav(
            synthesizer_config=self.synthesizer_config,
            file=wav_data,
            message=message,
            chunk_size=chunk_size,
        )
        
        return result
    
    @staticmethod
    async def get_voices_list():
        """åˆ©ç”¨å¯èƒ½ãªå…¨éŸ³å£°ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        voices = await edge_tts.list_voices()
        japanese_voices = [v for v in voices if v["Locale"].startswith("ja-JP")]
        
        print("\nåˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªéŸ³å£°:")
        for voice in japanese_voices:
            print(f"- {voice['ShortName']}: {voice['Gender']} ({voice.get('FriendlyName', 'N/A')})")
        
        return japanese_voices