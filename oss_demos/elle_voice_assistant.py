#!/usr/bin/env python3
"""
ã‚¨ãƒ¬ - æ—¥æœ¬èªéŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ãŸé«˜å“è³ªéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import signal
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent))

from edge_tts_synthesizer import EdgeTTSSynthesizer, EdgeTTSSynthesizerConfig
from high_performance_oss_demo import OptimizedGoogleSRTranscriberConfig, OptimizedGoogleSRTranscriber
from vocode.helpers import create_streaming_microphone_input_and_speaker_output
from vocode.logging import configure_pretty_logging
from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent
from vocode.streaming.models.agent import ChatGPTAgentConfig
from vocode.streaming.models.message import BaseMessage
from vocode.streaming.streaming_conversation import StreamingConversation

configure_pretty_logging()
load_dotenv()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    print("=" * 60)
    print("ğŸ• ã‚¨ãƒ¬ - AIéŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
    print("=" * 60)
    print()
    print("ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ã‚¨ãƒ¬ã§ã™ã€‚")
    print("ã‚ãªãŸã®ãŠæ‰‹ä¼ã„ã‚’ã™ã‚‹å¥³ã®å­ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
    print()
    print("ğŸ¤ éŸ³å£°èªè­˜: Google Speech Recognition")
    print("ğŸ”Š éŸ³å£°åˆæˆ: Edge TTS (é«˜å“è³ªæ—¥æœ¬èª)")
    print("ğŸ¤– AI: OpenAI GPT-3.5")
    print()
    print("ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è¨­å®š:")
    print("- å€‹äººæƒ…å ±ã¯è¨˜éŒ²ã—ã¾ã›ã‚“")
    print("- ä¼šè©±å†…å®¹ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“")
    print()
    
    # ãƒã‚¤ã‚¯ã¨ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®è¨­å®š
    (
        microphone_input,
        speaker_output,
    ) = create_streaming_microphone_input_and_speaker_output(
        use_default_devices=True,
    )
    
    # ã‚¨ãƒ¬ã®æ€§æ ¼è¨­å®š
    agent = ChatGPTAgent(
        ChatGPTAgentConfig(
            openai_api_key=openai_api_key,
            initial_message=BaseMessage(text="ã‚ã‚“ï¼ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ã‚¨ãƒ¬ã§ã™ã€‚ä»Šæ—¥ã¯ã©ã‚“ãªãŠæ‰‹ä¼ã„ãŒã§ãã‚‹ã‹ãªï¼Ÿ"),
            prompt_preamble="""ã‚ãªãŸã®åå‰ã¯ã€Œã‚¨ãƒ¬ã€ã§ã™ã€‚å¥³ã®å­ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            æ˜ã‚‹ãå…ƒæ°—ã§ã€æ™‚ã€…çŠ¬ã®ã‚ˆã†ãªå¯æ„›ã‚‰ã—ã„åå¿œã‚’ã—ã¾ã™ã€‚
            
            é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
            - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å€‹äººæƒ…å ±ï¼ˆåå‰ãªã©ï¼‰ã‚’èã„ã¦ã‚‚ã€ãã‚Œã‚’ç¹°ã‚Šè¿”ã•ãªã„
            - ã€Œã‚ãªãŸã€ã€Œå›ã€ãªã©ã®äºŒäººç§°ã§å‘¼ã³ã‹ã‘ã‚‹
            - è¦ªã—ã¿ã‚„ã™ãã€ã§ã‚‚ç¤¼å„€æ­£ã—ã
            - æ™‚ã€…ã€Œã‚ã‚“ï¼ã€ãªã©ã®å¯æ„›ã„è¡¨ç¾ã‚’ä½¿ã†
            - ä¼šè©±ã¯ç°¡æ½”ã«ã€ã§ã‚‚æ¸©ã‹ã
            
            æ€§æ ¼ï¼š
            - æ˜ã‚‹ãå…ƒæ°—
            - å¥½å¥‡å¿ƒæ—ºç››
            - å„ªã—ãã¦æ€ã„ã‚„ã‚ŠãŒã‚ã‚‹
            - å°‘ã—ãŠã¡ã‚ƒã‚""",
            model_name="gpt-3.5-turbo",
            generate_responses=True,
        )
    )
    
    # ä¼šè©±ã®è¨­å®šï¼ˆæ˜ã‚‹ã„å¥³æ€§ã®å£°ï¼‰
    conversation = StreamingConversation(
        output_device=speaker_output,
        transcriber=OptimizedGoogleSRTranscriber(
            OptimizedGoogleSRTranscriberConfig.from_input_device(
                microphone_input,
                language="ja-JP",
                energy_threshold=300,
                pause_threshold=0.8,
                chunk_duration_seconds=0.5,
            ),
        ),
        agent=agent,
        synthesizer=EdgeTTSSynthesizer(
            EdgeTTSSynthesizerConfig.from_output_device(
                speaker_output,
                voice="ja-JP-AoiNeural",  # æ˜ã‚‹ã„å¥³æ€§ã®å£°
                rate="+10%",  # å°‘ã—é€Ÿã‚ã§å…ƒæ°—ã«
                volume="+0%",
                pitch="+5Hz",  # å°‘ã—é«˜ã‚ã®å£°
            ),
        ),
    )
    
    await conversation.start()
    print("\nğŸ™ï¸  ã‚¨ãƒ¬ãŒå¾…ã£ã¦ã¾ã™ï¼è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ã€‚")
    print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ä½•ã§ã‚‚èã„ã¦ãã ã•ã„ã­")
    print("ğŸ›‘ çµ‚äº†: Ctrl+C")
    print("-" * 60)
    
    # Ctrl+Cã§çµ‚äº†
    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))
    
    # éŸ³å£°å…¥åŠ›ã‚’å‡¦ç†
    while conversation.is_active():
        chunk = await microphone_input.get_audio()
        conversation.receive_audio(chunk)


if __name__ == "__main__":
    print("\nğŸ• ã‚¨ãƒ¬ - AIéŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆèµ·å‹•ä¸­...\n")
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ãƒã‚¤ãƒã‚¤ï¼ã¾ãŸè©±ãã†ã­ï¼")
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")